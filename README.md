# Practical Reinforcement Learning Schedules
RL Study schedules. It includes plans, studies, projects, assignments


##0724
2주나 쉬었네요! 금일은 스터디있는 날입니다.

1. 여러분 Cartpole v0말고 어려운 버젼을 10초도 안되는 시간에 학습하는걸
바로 구현하고 결과를 눈으로 보고 싶으신가요?  A3C 코드 구현 오늘 합니다.
(위의 아름다운 Plot을 보세요)

2. 엘레베이터 환경에 대해서 살펴보고, 간단하게 트레이딩 짐 돌려보는것도 해볼 예정입니다. 

엘베 빼곤 거의 실습 위주로 돌려볼 생각이니깐요~ 여러분들도 노트북을 챙겨오시면 좋을 것 같아요! 12시까지 투표해주시고요 오늘 많은 참석부탁드립니다.



## 0717 (참석자 저조로 쉬어감)
금일 스터디는 A3C 코드 구현과 엘레베이터 환경에 대해서 살펴보고, 간단하게 트레이딩 짐 돌려보는것도 해볼 예정입니다.
엘베 빼곤 거의 실습 위주로 돌려볼 생각이니깐요~ 여러분들도 노트북을 챙겨오시면 좋을 것 같아요! 12시까지 투표해주시고요 이따가 뵙겠습니다~


## 0710

금일 스터디는 뒷풀이 참석하시는 분들을 좀 늘리기 위해 스터디를 짧게 합니다. 시간은 아무리 길어도 1시간 반 이내로 생각하고요, 박영준 박사님을 모시고 특별 세션을 가집니다. 세션 내용은 다음과 같구요, 스터디 투표 부탁드립니다. ^^

<세션 내용>
딥러닝의 발전으로 최근 강화학습이 다양한 분야에서 활발히 연구되고 있다. 하지만 많은 연구는 한 개의 에이전트만을 다루는 싱글 에이전트 문제만을 다루고 있다. 현실 문제에서는 다수의 에이전트를 컨트롤 해야 하는 경우가 많으며 이러한 경우 멀티에이전트 강화학습이 필요하다. 따라서 본 연구에서는 멀티에이전트 간의 협동과 경쟁을 학습시킬 수 있는 강화학습 알고리즘에 대해 다루고자 한다. 특히 본 연구에서는 Recurrent layer를 사용하여 에이전트 간의 통신을 가능하게 하여 각각의 에이전트가 관측한 정보를 취합하여 의사결정을 내릴 수 있는 방법론을 제안하였다. 또한 모델 기반 강화학습의 아이디어를 이용한 approximate model learning을 활용하여 에이전트가 환경의 다이내믹스를 이해하도록 하여 보다 빠르게 학습할 수 있는 방법론을 제안하였다

<추가 소식>
좋은 소식(제안)이 있어 말씀드립니다. 여기 OB 멤버들은 아시는 분인데 송동근(동근당)님이 7월말부터 합류를 하게 됩니다. 통계석사마치시고 네이버엔터테인먼트를 거쳐 버즈니라는 회사에서 데이터사이언티스트로 활동중입니다. 저희 스터디에 와서 강화학습외에도 머신러닝쪽( 딥러닝 기초, 통계, 확률) 스터디가 동근당님 통해서 많이 이뤄질 예정이구요,  나중에 카톡방에 초대할테니 열렬한 환영 부탁드립니다 ^^


## 0703
여러분 오늘도 스터디 있는날이네요,

1. Trading gym introduction (조태현님)
2. saida-rl introduction
3. 시간 남을 경우 a3c 실습

차주에 박영준박사님의 졸업논문이자 저와 같이 했던 연구에 대해서 다룰 예정이니 많은 관심 가져주세요~
12시까지 그럼 투표 부탁드리구요!!



## 0626
재구님 덕분에 좋은 경제&부동산 세미나 시간을 가지 데이터 시각화가 잘되어있는 인사이트 돋는 리치고 시스템 구경도 했습니다.



## 0619
페이스북이 리브라라는 가상화폐를 꺼내놓았네요 다들 상상하던 것들이 조금 빨리 다가온 느낌인가요? ^^
스터디가 3주 쉬었네요~ 금일은 지난시간에 할려고 했던 합니다.

1. 일주님이 SAIDA RL 논문 1편 소개와 설치에 대한 가이드를 해줄 예정입니다
2. 시간이 허락한다면 A3C 논문 정리하고 코드 구현 들어가볼까 합니다.

투표 12시까지 해주시고요,
오늘은 스터디 이후 책 저자분들은 DQN과 A3C 정리한 것 가지고 얘기함 해보시죠 ^^ 


## 0612
지난 2주가 흘렀네요. 금일은 지난시간에 할려고 했던 합니다

1. 일주님이 SAIDA RL 논문 1편 소개와 설치에 대한 가이드를 해줄 예정입니다. 지난번 공유한거 출력해오시면 더 좋을 듯 합니다.
2. 시간이 허락한다면 A3C 논문 마저 정리하고 코드 구현 들어 갑니다.  

오늘 투표 내일 12시까지 해주시고요, 참고로 논문은 아직 학회 리뷰상태라 배포금지합니다.
오늘은 스터디 이후 책 저자분들은 DQN과 A3C 정리한 것 가지고 얘기함 해보시죠 ^^ 


## 0605
지난 1주 잘 쉬었나요? 일주/현제님과 같이 논문 2편이 완성이 되었고 SAIDA RL 오픈소스 링크 드렸는데요.

1. 이 환경에서 해보고 싶으실 분들 위해 일주님이 SAIDA RL 논문 1편 소개와 설치에 대한 가이드를 해줄 예정입니다. 공유해드리오니 출력해오시면 더 좋을 듯 합니다.
2. 시간이 허락한다면 A3C 논문을 마저 정리하고 코드 구현 들어갑니다.  

오늘은 일찍 공지를 하네요^^
투표 내일 12시까지 해주시고요, 참고로 논문 아직 리뷰상태이지만 공유합니다.

참, 책 저자분들은 DQN과 A3C 제가 공유한 PDF처럼 다 공유해주시길 바랍니다.


## 0529
최초로 제 개인 사정인...논문 제출이 코앞이라 한주 쉬어갑니다. 


## 0522
여러분~ 오늘은 험프데이! 스터디있는날입니다. 지난 시간 이현제/조태현님의 너무 쏙쏙 잘들어오는 유익한 발표 잘들었습니다.
자주 이런 세션을 마련하는것도 좋은 것 같습니다. 정리하면서 전문가가 되는거겠죠~

1. 오늘은 수영님의 "데이터사이언티스트의 하루" 
2. DDPG 
     - 논문 "CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING"
     - https://arxiv.org/pdf/1509.02971.pdf
     - [RLKorea](https://www.slideshare.net/ssuser41d7e01/ddpg-deep-deterministic-policy-gradient-139832691?fbclid=IwAR0nbdDMGZRQUvkIs7LPctsjCfJ-crlB_M0vf4_RV_iDGQG6JjHmEIj8TSg)
3. A3C 
     - 논문 "Asynchronous Methods for Deep Reinforcement Learning"
     - https://arxiv.org/abs/1602.01783

12시까지 투표해주시고요 분량은 위에 뽑았으나, 오늘은 좀 일찍 마치고
@"실전편"저자분들 동석님이 집필 계획을 공유하실겁니다.

## 0515
여러분~ 3번 연속으로 쉰건 처음인듯.

1. 여친이 생겨 행복한 남자 조태현님이 "행복한 퀀트 개발자의 하루는 어떨까?"라는 타이틀을 가지고 30분정도 발표하고 워렌버핏 버크셔헤서웨이 주주총회 얘기도 같이 좀 전달해주심 좋을것 같네요.
2. PPO논문을 이현제님이 발표를 30분 정도 발표를 할껍니다.
2. DDPG논문 마무리 정리합니다.  
     - "CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING"
     - https://arxiv.org/pdf/1509.02971.pdf
     - [참고자료](https://www.slideshare.net/ssuser41d7e01/ddpg-deep-deterministic-policy-gradient-139832691?fbclid=IwAR0nbdDMGZRQUvkIs7LPctsjCfJ-crlB_M0vf4_RV_iDGQG6JjHmEIj8TSg) (오늘 RLKorea에서 본 따끈한 자료)
3. (시간이 난다면) 멀티에이전트 작동하는 데모를 보여드릴게요 (재미난 환경이 있습니다)

12시까지 투표해주시와요!!!


## 0508 (참석저조로 스킵)
여러분~ 노동절은 잘 쉬었나요? 금일은 간만에 스터디있는 날이어요. 지지난 시간 그대로 진행할려고 합니다.

1. 여친이 생겨 행복한 남자 조태현님이 "행복한 퀀트 개발자의 하루는 어떨까?"라는 타이틀을 가지고 30분정도 발표합니다.
2. PPO논문을 이현제님이 발표를 30분 정도 발표를 할껍니다.
2. DDPG논문 마무리 정리합니다.  
     - "CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING"
     - https://arxiv.org/pdf/1509.02971.pdf
     - [참고자료](https://www.slideshare.net/ssuser41d7e01/ddpg-deep-deterministic-policy-gradient-139832691?fbclid=IwAR0nbdDMGZRQUvkIs7LPctsjCfJ-crlB_M0vf4_RV_iDGQG6JjHmEIj8TSg) (오늘 RLKorea에서 본 따끈한 자료)
3. (시간이 난다면) DDPG 소스코드를 보여드리고 데모도 살짝 보여드릴까 합니다   -> 실습을 위한 예열준비

12시까지 투표해주시와요!!



## 0501(노동절로 스킵)


## 0417 (참석자 미달로 스킵)
금일도 어김없이 스터디가 있는 날입니다. 
전 어제 SI시절 오래 같이 일했던 후배가 보자 해서 한잔 찐하게 하며 참 많은 생각이 들었습니다. 기술이 꽤 좋은 친구인데 변화를 싫어하는 친구라 자바, 자바스크립트외에 다른데는 1도 관심이 없던 친구가 갑자기 파이선하고 AI공부하겠다고 하네요.  뭔가 기분이 묘했습니다 ^^


자, DPG 논문을 살펴보느라 너무 힘드셨죠? 그래서 이번에 살짝 재미난 시간을 마련했습니다. 

1. 여친이 생겨 행복한 남자 조태현님이 "행복한 퀀트 개발자의 하루는 어떨까?"라는 타이틀을 가지고 30분정도 발표합니다.
2. DPG논문을 살짝보고 DDPG논문을 다룰려고 합니다.  
     - "CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING"
     - https://arxiv.org/pdf/1509.02971.pdf
     - [참고자료](https://www.slideshare.net/ssuser41d7e01/ddpg-deep-deterministic-policy-gradient-139832691?fbclid=IwAR0nbdDMGZRQUvkIs7LPctsjCfJ-crlB_M0vf4_RV_iDGQG6JjHmEIj8TSg) (오늘 RLKorea에서 본 따끈한 자료)
3. (시간이 난다면) DDPG 소스코드를 보여드리고 데모도 살짝 보여드릴까 합니다   -> 실습을 위한 예열준비

아 그리고, 김주철님/이동석님하고 전 일찍 퇴근해서 강남 CGV에서 영화봅니다. (헬보이, 15:35 ~ 17:46)  
당연히 다들 안되시겠지만 혹시 보고 싶으신분은 조인하세요,  
그리고 6시~7시반까지 M2 바로 옆 "아띠제"에서 집필계획서 작성완료해서 출판사에 넘길 계획입니다.
혹시 시간 여력되시는 (책 저자분들은) 6시 아띠제로 오시면 되겠습니다.

12시까지 투표해주세요 감사합니다.




## 0410
금일도 어김없이 스터디가 있는 날입니다. 비가 부슬부슬오더니 그쳤네요 

지난번에 PG 계열의 첫걸음인 REINFORCE 코드 구현 실습했습니다.
다들 한번 코드 구현하신거 손을 봐서 CartPole이 잘 작동하는거 눈으로 확인하셨으면 좋겠습니다.
https://github.com/practical-rl-study/sources/blob/master/ukjo/190403_REINFORCE.py

오늘은 DPG 논문을 다룰 예정입니다. 
materials 리스트중 6번 항목이구요, 요즘 state of art 찍고 있는 알고리즘들이 대부분 이 논문을 기반으로 하고 있습니다.
https://arxiv.org/pdf/1709.05380

이 논문도 상당히 중요하곘죠? 아 그리고 남는 시간에 책 쓰는것에 대한 잠깐 얘기도 같이할까합니다. (오늘은 기필코 ㅋㅋ)
12시까지 투표해주세요 감사합니다.

----
어제 내용 정리한거 공유해주시고, 공동편집 가능한 공간은 어디가 좋을까 골라서 집필계획서 올려주세요

기본편(윤일주님 리딩) - 윤일주 이현제 박수영 김주철 이동석 조억 (5명)

실전편(이동석님 리딩) - 이동석 조태현 윤일주 이현제 허재영 조억 (5명)

책을 쓰면 좋은 점  https://brunch.co.kr/@parisboys/130


그리고 아래 가보시면 README에 프로필을 올릴까합니다. 아래 예시 한번보세요 
https://github.com/practical-rl-study/sources/blob/master/README.md




## 0403
금일도 어김없이 스터디가 있는 날입니다.  

지난번 예고했듯이 PG 계열의 첫걸음인 REINFORCE 코드 구현 실습합니다
노트북들고오면 더욱더 좋겠죠? 직접해보면서 결과 보면 재미가 쏟구쳐요!!
시간남는다면(아마 경험상 안남지 않을까) 어제 공유했던 논문 간략한 소개와 
책 쓰는것에 대한 얘기도 같이할까합니다. 그리고 지난 시간 논문 리뷰자료는 
깃헙에 금일중으로 올리겠습니다

12시까지 투표해주세요 감사합니다.

----

공지합니다.

1. 책 출간 
여럿차례 걸쳐서 말씀드려서 이제 다 아시다시피,
올해 저희 스터디에서 책을 2권 출간할 예정입니다. 
저자는 아래처럼 가고요, 집필계획서에 저자정보부터 
첨부의 9번 항목 채워서 먼저 보내주시고 그리고 나머지 
부분도 작성 여유되시는 분 작성해서 공유해주시면 감사하겠습니다 
이동석/윤일주님하고 지난주 간단하게 얘기는 했고 그 기준으로
내용을 채우고 있겠습니다.

기본편 - 윤일주  (조태현) 이현제 박수영 이동석  조억 (5명)
실전편 - 이동석 윤일주 이현제 허재영 조억 (5명)
미정 - 김재구 김주철

2. 실습소스 공유
어제 REINFORCE 소스 올립니다. 참고하세요, 

https://github.com/practical-rl-study/sources/blob/master/ukjo/190403_REINFORCE.py




## 0327
안녕하세요 오늘도 스터디있는 날입니다. 

금일은 
1. 스타크래프트와 강화학습 (윤일주님)
2. Policy Gradient Methods for Reinforcement Learning with Function Approximation (조억님)

2번은 내용이 많이 어려운듯하여 안오신분까지 고려해서 한번 더 리뷰할 생각입니다. 
많은 참석 부탁드리며 12시까지 답변 주시기 바랍니다.



## 0319
간만에 공지하는데 느낌이 이상하네요ㅎ 지난 수요일 못오신분들 많아 아쉬웠지만 즐거웠습니다. 스터디는 제가 눈이 이상해지기전까지 DRQN 논문을 봤었죠, 이제 Policy gradint 계열의 서막을 알리는 논문인 "Policy Gradient Methods for Reinforcement Learning with Function Approximation"에 대해서 다루겠습니다. 내일 오후 12시까지 참석투표해주세요

https://github.com/practical-rl-study/materials 에 5번에 논문 정보있습니다.


## 1128
안녕하세요~ 오늘은 스터디있는날 입니다. 
실습 2가지로 진행됩니다.

1. Frosbite 게임에다가 DRQN 적용해서 돌아가는걸 해볼 예정이며, 논문에도 1만 에피소드 이상이 걸리기때문에 결과는 따로 확인해야 할 것 같구요.
2. DQN도 Dueling, Double 적용한것 질문받고 안되는 부분 같이 살펴볼 예정입니다.

12시까지 알려주세요~~

## 1121
복귀하신 박수영님 환영합니다!! 이번에는 DRQN을 가지고 했습니다. 아타리게임 2600 [28] [Frostbite](https://www.youtube.com/watch?v=dl1jGOu5No0) 이 어려운 게임을 이기는 DQN의 variant를 살펴보았습니다. 

![](./Frostbite_v0_openai.gif)


double & dueling dqn 구현을 저희가 만든 dqn에 넣어보는것 
파라메터를 다양하게 줘서 모든 조합을 한번에 돌리는 로직 실습했습니다.
이부분도 최대한 코드 설명한 버젼에서 보완해서 돌아가는 코드로 올리도록 하겠습니다~ 

## 1114
석정님이 Dueling DQN(Dueling Network Architectures for Deep Reinforcement Learning, Z. Wang et al., arXiv, 2015) 논문 리뷰해주셨습니다. 관련 문서도 materials에 올렸으니 참조바랍니다. 또한 빠른 속도를 위해 appendix에 있는 Double DQN에 대해서도 다루었습니다.  다음시간은 코드 구현을 직접해보면서 간단히 DQN에 적용해보도록 하겠습니다.

## 1107
오늘 스터디는 DQN을 맨땅부터 코딩해서 완전히 이해하고 마무리하는 시간을 가질게요. 각자 노트북 지참하면 좋겠죠? 12시까지 알려주세요!!


## 1031
참석 인원 3명으로 쉬어감

## 1024
DQN 논문 2015년 버젼(Human-level control through deep reinforcement learning, V. Mnih et al., Nature, 2015.)  리뷰


## 1017
### Before
다들 주말에 아이디어 생각을 좀 해보셨는지요? ^^
 
1. 금주안에 새로운 주제 선정할거구요,  금주 수욜 아이디어 나온것 가지고 불참 회원들도 온라인 voting할 수 있게 할게요  https://goo.gl/bW1j1K

2. 저조한 참석율로 멤버증원의 차원으로 신규 멤버 소식이 있습니다. 송석정님이고 경희대 박사과정 밟고 모두연 강화학습 DLC반입니다.   현재 저 포함 12명인데요, 15명정도면.. 그래도 최소 매주 5명 정도는 모이지 않을까해서요 30%이상만 모이면 되니까요.  주변에 꾸준히 나올 멤버 있으면 언제든 알려주세요. 꾸준함이 살길입니다^^

그럼 금주 수요일은 왠만하면 다들 나오셔서 같이 간만에 안부도 묻고 좋은 시간 가졌으면 좋겠습니다.


### After
오늘 간만에 뵙는 주철님과 그리고 새로오신 석정님, 그리고 늘 꾸준히 참석해주시는 동석님 그리고 재영님 이렇게 4분과 스터디 진행 방향에 대해서 얘기를 시간 가는줄 모르고 나눈 것 같습니다. 우선 석정/재영님은 강화학습을 생각하고 들어오셨고 나머지분들도 강화학습을 메인으로 하는게 맞다라는 얘기였고요, 
의도된바는 아닌데 살짝 회고 하는 시간을 가져봤구요.  여튼 진행하면서 놓친 부분 더 잘 할수 있는 많은 부분을 피부로 느낄수 있었고요, 

정리하자면, 
1. 우선 RL이다.
2. 이론만 아는것보다는 구현에 대해서 실력이 쌓였으면 좋겠다.
3. 논문을 쓸 뗄깜으로 주제를 잡아갔으면 좋겠다.
4. 스터디를 함에 있어서 휘발성이 아니라 쌓여가는 게 있었으면 좋겠다.
5. 공모전 같은데 나가봤으면 좋겠다 (이건 지난주 참석했던 멤버들과 얘기도 같이 겸해서)
6. 동석님 의견인데 짧게 치고 나가는게 있었으면 좋겠다.

이런 의견들을 적극 모두모두 반영해서, 방향은 강화학습의 root 뿌리가 되는 중요 알고리즘 논문과 그 variants(변종)들중 유명한것들만 해서 top 10개를 list up해서 구현 해보는걸 해보기로 했습니다. git repository를 관리할거고 그리고 논문 리뷰는 쉽게 정리해서 공유하고 그리고 구현을 한번씩 해보는걸로 해보는거죠. 논문에 대한 두려움은 없으셔도 됩니다. 저와 석정님이 support를 할거고요. 구현 쪽을 엔지니어분들은 좀 이참에 아이디어를 어떻게 녹일지를 고민해보면서 2018년도 올해 내내 배운것들을 다시 다지는 시간을 가지면 좋겠습니다. 10개 잘 따라오시면 충분히 가능합니다.  

마지막으로, 제가 스터디 주제도 너무 광범위하게 가져간것도 조금 잘못했나 싶기도 하고 먼저 얘기해보고 그다음에 준비된 주제를 공유드린것도 좋지 않았을까 생각이 들었네요. 참. 회비가 앵꼬네요. -30이나.. 한번 걷겠습니다. =-=





## 1010
강화학습 기초부터 value based의 알고리즘 DQN부터 policy based 알고리즘 REINFORCE 그리고 A3C까지 다루었습니다. 
재구님과 경일님과 함께 여태까지의 스터디 히스토리와 그리고 아이디어 회의를 하였습니다.

아래는 아이디어 안들입니다.
https://goo.gl/bW1j1K



## 0918
오늘 스터디 있는날입니다!! 7시반이구요! 보시고 바로 답주세요~ 늦어도 12시까지 답주셔야되요! 지난 시간 빠르게 PG 모델인 REINFORCE훑고 바로 A3C 코드까지 살펴보고 얼마나 빨라지는지 느끼셨을거라 생각됩니다. 이번엔 A3C를 pytorch로 짜보는 실습을 해보는걸로 할까합니다. 직접 한줄한줄 짜볼려고 합니다. 그리고 제가 회사에서 진행중인 스타크래프트 강화학습 모델을 한번 설명드리고 강화학습 적용할 때의 당면했던 문제/트러블슈팅도 설명드릴려고 합니다.


## 0912
1. 지난 시간에 PG 모델인 REINFORCE를 짜보는 실습을 PYTORCH와 Keras로 진행했습니다. 아래는 소스코드이구요, 슬랙에 plot도 공유했었죠?
https://gitlab.com/iljoo.yoon/rl-study/blob/master/src/study/180808_reinforce_using_pytorch.py
https://gitlab.com/iljoo.yoon/rl-study/blob/master/src/study/180808_reinforce_using_keras.py
그때 온 분들이 적어서 다시 한번 살짝 다루고요

2. A3C Cartpole 코드를 살펴보는 시간을 가지겠습니다. 얼마나 빨라지는지 보시길 ^^ 그 다음에는 이걸 직접 짜보는 pytorch로 실습을 해보는걸로 하곘습니다.

3. 지지난주부터 공지했던 재미난 실습을 시작해볼려고 합니다. 욕심안내고 그냥 파이선으로 네이버에 있는 종목게시판 제목을 쭉 긁어와서 파일로 저장하는 데이터 수집만 먼저 다루겠습니다.


## 0905
오늘 스터디 있는날입니다. 7시반이구요, 보시고 바로 답주세요~ 늦어도 11시까지 말씀해주세요, 참 AI Forum 오시는분 있으신가요?

1. 지난 시간에 PG 모델인 REINFORCE를 짜보는 실습을 PYTORCH와 Keras로 진행했습니다. 아래는 소스코드이구요, 슬랙에 plot도 공유했었죠?
https://gitlab.com/iljoo.yoon/rl-study/blob/master/src/study/180808_reinforce_using_pytorch.py
https://gitlab.com/iljoo.yoon/rl-study/blob/master/src/study/180808_reinforce_using_keras.py
그때 온 분들이 적어서 다시 한번 살짝 다루고요

2. A3C Cartpole 코드를 살펴보는 시간을 가지겠습니다. 얼마나 빨라지는지 보시길 ^^ 그 다음에는 이걸 직접 짜보는 pytorch로 실습을 해보는걸로 하곘습니다.

3. 지지난주부터 공지했던 재미난 실습을 시작해볼려고 합니다. 욕심안내고 그냥 파이선으로 네이버에 있는 종목게시판 제목을 쭉 긁어와서 파일로 저장하는 데이터 수집만 먼저 다루겠습니다.

오늘 저번에 합류해서 인사했던 김경일님도 오실수 있음 좋겠네요~
제주도에 있는 동석님 오늘 저녁뱅기인데 오실수 있음 오시고, 참석가능하신분 12시까지 말씀해주세요,
아 그리고 오늘 스터디는 7시반이 아니라, 8시에 하겠습니다.


## 0824
제가 차주 수요일까지 학회 논문 제출이라 여유가 없어서 멤버분들에게 죄송하네요. 이번 포함하면 스터디 3주째 쉬고 있습니다. 차주도 논문 일정에 따라 한주 더 쉬어갈지도 모릅니다. 여튼 폭염/휴가철도 갔으니 본격적으로 재가동할 예정이에요~^^ 다시 새로운 멤버 2분(한분 더 올지도) 와서 재미있게 진행토록 하겠습니다. 스터디 운영을 어떻게 했으면 좋겠다 라는 의견도 주시면 좋을 것 같네요.

## 0822
날씨가 많이 선선해져서 살맛나는 요즘이네요, 오늘도 스터디 있는날입니다^^   
1. 지난 시간에 PG 모델인 REINFORCE를 짜보는 실습을 PYTORCH와 Keras로 진행했습니다. 아래는 소스코드이구요, 슬랙에 plot도 공유했었죠?
https://gitlab.com/iljoo.yoon/rl-study/blob/master/src/study/180808_reinforce_using_pytorch.py
https://gitlab.com/iljoo.yoon/rl-study/blob/master/src/study/180808_reinforce_using_keras.py
그때 온 분들이 적어서 다시 한번 살짝 다루고요

2. A3C Cartpole 코드를 살펴보는 시간을 가지겠스빈다. 그 다음에는 이걸 직접 짜보는  pytorch로 실습을 해보는걸로 하곘습니다.
3. 지지난주부터 공지했던 재미난 실습을 시작해볼려고 합니다.  
욕심안내고 그냥 파이선으로 네이버에 있는 종목게시판 제목을 쭉 긁어와서 파일로 저장하는 데이터 수집만 먼저 다루겠습니다.

오늘 저번에 합류해서 인사했던 김경일님도 오실수 있음 좋겠네요~
완준님에 이어 말레시시아를 가는 태현님 빼고 참석가능하신분 12시까지 말씀해주세요,
아 그리고 오늘 스터디는 7시반이 아니라, 8시에 하겠습니다. 

## 0814

- 김경일님 합류

공지 드립니다
1. 내일은 광복절이라 하루 쉬어갑니다. 일정 조율에 차질 없으시길 바랍니다.
2. 공지사항 하나더!! 멤버 한명이 충원됩니다. 이동석님과 같이 회사 동기인데요, 김경일님이라고..
강화학습부터 딥러닝까지 더 늦기전에 배워야겠다고 합류 꼭 하고 싶다고 합니다^^ 이분은  회사에서 제가 하는 스타크래프트에 강화학습 적용도 했었어요~ Q 테이블 써서 하는 Q Learning 가지고 말이죠. 밑바닥책과 DQN정도는 다 공부하고 넘어오셔서 저희 진도 맞추기에도 문제 없을듯합니다. 김경일님은 와서 강화학습 컴피티션도 나가보자고 제의를 먼저 하시네요~
3. 참 지난번에 못했던 재미난 실습을 먼저 할려고 합니다.  네이버 주식 종목게시판에 제목 크롤링해서 감성분석해서 RNN분석하는거 해보는거 재구님외에 지원자 없나요?

재구님하고 동석님 다른 부분 하고 싶으심 말씀해주세요 !!

차주에 있을 실습입니다. @김재구님  @이동석님 follow up 잘 부탁드립니다 ㅋㅋ

주제 : 네이버 뉴스 종목게시판이 글 제목 읽어와서 일별 변수로 정의하고 RNN 이용한 주가 가격 트렌드 예측할려고 합니다.

예1) 얼마나 곡소리가 나와야 저점을 다지고 다시 오르는가를 알아보자는 등..

1) 제목 크롤링하는것 (조억 : 재구님이 잘하시겠으나, 텍스트마이닝 패캠에서 들으셨으니 리마인드차원에서 피처 뽑는걸 하시지요!!)
https://finance.naver.com/item/board.nhn?code=015760

2) 형태소 분석 및 감정 이외에 특징을 뽑아낼것 키워드 리스트업 (김재구님)
아래는 그냥 꼬꼬마랑 감성분석 플러그인 링크인데요 어떤것이어도 좋습니다.
@조태현님이 아이디어좀 주시는것도^^  사실 제일 중요한 단계라고 생각됩니다.
  http://kkma.snu.ac.kr/documents/
  https://github.com/mrlee23/KoreanSentimentAnalyzer

3) 일별 피처 생성을 위한 전처리 (이동석님)

4) 시점별 피쳐 RNN 모델 디자인 및 개발  (조억)

5) 모델 검증 및 향후 적용 아이디어 브레인스토밍 (조억)



## 0808
휴가철/폭염때문에 4주째 쉬고 있네요. 저희 스터디 있는날입니다. 가능하신 분들은 12시까지 답을 주세요. Policy Gradeint 계열의 강화학습의 알고리즘 중 첫 관문인 REINFORCE를 짜보는 실습을 진행할 예정입니다. 그것도 재구님이 추천한 PYTORCH로.. 저도 공부해가면서 할거라.. 이거 하나만 욕심안내고 할 생각입니다. 그리고 어제 제안한 건, 재구님외에 지원자 없나요? 이걸 위해 크롤링하고 감성분석하고 RNN이 필요한데요, 우선그중 하나인 rnn을 다룰 예정입니다. 제안한 실습은 다음주에 지원자 한명 더 모집되면 차주에 진행하겠습니다!

## 0801
휴가철이기도 하지만 스터디가 폭염때문에 뜨문뜨문하네요~ 하지만!! 스터디 오늘 있는날입니다. 가능하신 분들은 12시까지 답을 주세요. Policy Gradeint 계열의 강화학습의 알고리즘을 하나씩 짜보는 실습을 진행할 예정이고, RNN도 다룰 예정입니다. (이건 CNN보다 재미나요~~ 제 생각에 RNN은 아직 갈길이 멀지만 흥미로운 주제입니다 ㅋ) 뭐 어느 회원님 말씀처럼 휴가기간이니 연달아 쉬는것도 재충전시간이라 생각하며 건너 뛰는것도? 하지만... 진행합니다. 다수결로~^^

## 0725
찌는 폭염의 연속이네요ㅜㅜ 에어컨을 맨날 풀가동하다 한국전력 주식을 3일전에 살까 와이프에게 얘기했더니 진짜  그뒤로 계속 오르는중이네요~ 오늘 강화학습 스터디 있는 날입니다. 지난 시간에 A3C 까지 이론을 다뤘던 것 복습 간단히 하고 실습 단계로 넘어갑니다. REINFORCE부터 한번 보시죠~노트북 들고 오시면 될것같습니다. 휴가간 분들이 많아서 오늘 스터디 스킵해도 좋은날이었으면 하는 바램은 있으나 그래도 꾸준히 가시죠^^


## 0718
지난 한주 잘 쉬셨나요? 금일은 스터디있는 날입니다~^^
실용적으로 스터디를 추구하고자 매주 하나씩 실습해보는 시간을 가질겁니다.
쉬운 코드라 바로 그날 하나씩 완료할거고 그걸 github에도 각자 push 할까 합니다.(노트북가져오시면 좋겠죠?)
처음으로, CNN 모델 간단히 설명드리고, 모델 하나 만들어서 간단한 이미지 분류해보는것부터 하지요!
부담안가는선에서 코딩으로 완전한 배움으로 가는 과정으로 갈수 있게끔^^

이건 전의 공지내용 복붙..
지지난주 REINFORCE까지 했고 A3C 합니다. 잠깐 복습하고 A3C,A2C 나갑니다. 오늘 아마 Policy Gradient이론 슬라이드는 끝낼낼거 같네요. value based 강화학습 DQN까지는 실습을 조금 자율에 맡기고 제가 설명만 간단히 드리고 넘어갔는데 조금 자세히 다루면서 갑니다.  불참하시는 분만!!! 12시까지 참석여부 알려주시고요


## 0711
금일도 스터디있는 날입니다~^^ 지난주에 REINFORCE까지 했고 A3C 합니다. 잠깐 복습하고 A3C,A2C 나갑니다. 오늘 아마 Policy Gradient이론 슬라이드는 끝낼낼거 같네요. value based 강화학습 DQN까지는 실습을 조금 자율에 맡기고 제가 설명만 간단히 드리고 넘어갔는데 조금 자세히 다루면서 갑니다.  불참하시는 분만!!! 12시까지 참석여부 알려주시고요, 태현님은 예비군인거 알고 있으니 답변 안주셔도 됩니다.


## 0704
스터디 멤버 여러분 굳모닝입니다. 오늘 하늘 보셨나요? 정말 기가 막히네요 아까 출근길 찍은건데요! 날씨는 덥고 습해서 동남아날씨같지만 좋은 하루 보내길 바라겠습니다. 그리고 공지 ㅋㅋㅋ 오늘도 어김없이 스터디있는 날입니다. 지난시간에는 Policy Gradient 개념부터 PG Theorem 거쳐 Policy Graident의 시작인 REINFORCE까지 다루었습니다. 다시한번 복습하고 Actor Critic 계열 알고리즘 설명 들어가겠습니다. 그리고 원하시는 분이 있다면 증명을 하다가 중간에 stop했는데 논문이나 Richard Sutton책 열어놓고 PG Theorem 증명을 다루겠습니다. 그럼 12시까지 참석 여부 알려주세요, 있다가 뵙겠습니다!!~~


## 0627
오늘 우리 스터디있는 날입니다. Policy Graident 서론 얘기하면서 REINFORCE부터 Actor Critic 알고리즘을 아주 얄팍하게 다뤘는데 다시 한번 복습하구요 바로 REINFORCE를 심층적으로 다뤄볼려고 합니다. 12시까지 참석 여부 알려주세요, 있다가 뵙겠습니다!!

## 0620
안녕하세요 스터디 방학 잘 보내셨나요? 2주가 꽤 길게 느껴지네요~ 오늘 스터디날이며 주제는 드디어!! Policy Gradient 나가도록 하겠습니다.  오늘부터 자료는 다 공유를 드려서 출력을 하든가 할수 있도록 하겠습니다. DQN까지 잘 했다면 PG도 결코 어렵지 않을것 같구요, DQN처럼 오래 다룰 생각은 없고요 이거 끝나면 강화학습 배운 모델가지고 실습을 이것저것 하면서 손에 익히는 시간을 많이 가져가면 좋겠 다 생각이 들었습니다. 그리고 간단한 AE, GAN, LSTM, RNN, CNN등 딥러닝 모델도 간단히 Keras로 보는 시간도 가져보고 좀 이론말고 어플리케이션 측면을 강조해나갈까 합니다 ^^ PG가 어느정도 되고 나고 시간이 남는다면 Trading Gym과 Agent를 소개를 할려고 합니다. 이따 뵙겠습니다.  11시까지 참석여부 알려주시고요~ 간만에 뵈요!!


## 0606
모두의 연구소 멤버들 코딩캐프일정으로 스터디 한주 쉽니다.

## 0530
시간이 빠르네요~ 어제 태현님이 저보고 오늘 스터디하냐고 묻길래, 한다고 했더니 씨익 웃더라구요. 그래서 왜 그러냐니 좋아서요 라고 하더라구요. 진심인지 몰겠습니다. 여튼 그걸 확인하기위해서라도 ㅋ 오늘 스터디 진행합니다.  11시까지 알려주세요!! 
### 지난 시간
에는 DQN 까지의 이론을 새로 오신 김재구님 까지해서 한번 가볍게 언급하고 실습 버젼으로 DQN까지는 다루었습니다. 오늘은 그 업그레이드 버젼에 대한 이론을 근간하는 코드를 보이면서 구현까지 내용을 마무리 하고, 
### 오늘은 
드디어 Policy graident로 처음이니 쉽게 다룰 예정입니다. 오늘 참석이 어려우신 분은 오전11시까지 알려주시구요, 지난시간에 3분이 갑자기 급 못오셔서 공간비를 그대로 냈답니다. 물론 일때문이니 어쩔수 없지요 ^^ 
#### 차주 
쉽니다. 참고로 차주에 저, 태현님, 완준님은 모두의 연구소에서 단타 에이전트 봇 만들러 세부로 코딩캠프를 떠납니다. 그래서 스터디 한주 쉽니다. 다녀오면 아마 주식 단타치는 에이전트 돌아가는거 소개하는 시간을 따로 만들게요


## 0523
김재구님 합류
오늘 스터디는 진행합니다. 저번에 DQN 까지의 이론을 다루었는데 이론을 다시 한번 새로 오실 김재구님을 위해 한번 가볍게 언급하고 DQN과 DQN 업그레이드 버젼에 대한 구현 파트 쪽 설명으로 넘어가겠습니다.. 오늘이 정말 마지막으로 DQN끝으로 하고 Policy graident로 넘어가기 마지막입니다. 오늘 참석이 어려우신 분은 오후1시까지 알려주시구요, 재구님은 오늘 모임 장소는 신논현에 M2 Space라고 교보타워 뒷편에 있는쪽으로 7시반까지 와주시면 됩니다.

그리고 제 아들은 의사 말로는 이제 최악은 지났다고 하네요~ 살면서 이렇게 마음이 아팠던적이 또 있었을까 싶습니다 ㅋ 우리 김주철님 작년에 맘고생하셨던거에 비하면 새발의 피겠지만요 말도 못하는 20개월 애기한테 혈관을 못찾아서 2시간 넘게 혈관을 쑤시는데 맴찢입니다 ㅜㅜ 회복하는데 좀 더 걸리겠지만 한숨 돌렸네요. 대신 와이프가 짐 그 바통을 이어 받아서 또 멘붕이지만 좋아지겠죠~ 다들 걱정해주셔서 감사합니다~

## 0518
동근당님, 이동석님, 윤병도님, 김주철님 빼면 6분 참석하시는걸로 알고 내일 10시에 컴퓨터 앞에 대기 부탁드리겠습니다. 스터디 내용은 영상 따로 녹화떠서 불참하신분들 볼 수 있도록 하겠습니다. 그리고 아까 말씀드린 투표 아래 링크에서 하실수 있습니다. https://mlwednesdaystudygroup.slack.com/archives/C9K3YCN5T/p1526613944000121



## 0514
온라인 행아웃으로 스터디


## 0509
안녕하세요~ 한주 잘 보내셨어요? 월요일이 휴일이라 금방 수요일이네요!! 지난 시간에는 value & policy iteration (이제 지겹죠?) 빠르게 훑고 그 녀석들의 한계점 그리고 바로 q learn
